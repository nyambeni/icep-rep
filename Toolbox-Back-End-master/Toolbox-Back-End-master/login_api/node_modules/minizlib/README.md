# minizlib

<<<<<<< HEAD
A fast zlib stream built on [minipass](http://npm.im/minipass) and
Node.js's zlib binding.

This module was created to serve the needs of
[node-tar](http://npm.im/tar) and
[minipass-fetch](http://npm.im/minipass-fetch).

Brotli is supported in versions of node with a Brotli binding.
=======
A tiny fast zlib stream built on [minipass](http://npm.im/minipass)
and Node.js's zlib binding.

This module was created to serve the needs of
[node-tar](http://npm.im/tar) v2.  If your needs are different, then
it may not be for you.
>>>>>>> f29eaf297270082f856cab0448210d31fc09283f

## How does this differ from the streams in `require('zlib')`?

First, there are no convenience methods to compress or decompress a
buffer.  If you want those, use the built-in `zlib` module.  This is
<<<<<<< HEAD
only streams.  That being said, Minipass streams to make it fairly easy to
use as one-liners: `new zlib.Deflate().end(data).read()` will return the
deflate compressed result.

This module compresses and decompresses the data as fast as you feed
it in.  It is synchronous, and runs on the main process thread.  Zlib
and Brotli operations can be high CPU, but they're very fast, and doing it
this way means much less bookkeeping and artificial deferral.
=======
only streams.

This module compresses and decompresses the data as fast as you feed
it in.  It is synchronous, and runs on the main process thread.  Zlib
operations can be high CPU, but they're very fast, and doing it this
way means much less bookkeeping and artificial deferral.
>>>>>>> f29eaf297270082f856cab0448210d31fc09283f

Node's built in zlib streams are built on top of `stream.Transform`.
They do the maximally safe thing with respect to consistent
asynchrony, buffering, and backpressure.

<<<<<<< HEAD
See [Minipass](http://npm.im/minipass) for more on the differences between
Node.js core streams and Minipass streams, and the convenience methods
provided by that class.

## Classes

- Deflate
- Inflate
- Gzip
- Gunzip
- DeflateRaw
- InflateRaw
- Unzip
- BrotliCompress (Node v10 and higher)
- BrotliDecompress (Node v10 and higher)

## USAGE

```js
const zlib = require('minizlib')
const input = sourceOfCompressedData()
const decode = new zlib.BrotliDecompress()
const output = whereToWriteTheDecodedData()
input.pipe(decode).pipe(output)
```
=======
This module _does_ support backpressure, and will buffer output chunks
that are not consumed, but is less of a mediator between the input and
output.  There is no high or low watermarks, no state objects, and so
artificial async deferrals.  It will not protect you from Zalgo.

If you write, data will be emitted right away.  If you write
everything synchronously in one tick, and you are listening to the
`data` event to consume it, then it'll all be emitted right away in
that same tick.  If you want data to be emitted in the next tick, then
write it in the next tick.

It is thus the responsibility of the reader and writer to manage their
own consumption and process execution flow.

The goal is to compress and decompress as fast as possible, even for
files that are too large to store all in one buffer.

The API is very similar to the built-in zlib module.  There are
classes that you instantiate with `new` and they are streams that can
be piped together.
>>>>>>> f29eaf297270082f856cab0448210d31fc09283f
